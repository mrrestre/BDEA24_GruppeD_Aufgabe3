{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c71809",
   "metadata": {},
   "source": [
    "# Aufgabe Beschreibung\n",
    "\n",
    "- Mindestens eine NoSQL DB verwenden (Docker, Docker-compose)\n",
    "- Lessons Learned wichtiger als optimale Lösung (Was hätte ich anders gemacht?)\n",
    "\n",
    "1. Abzugeben:\n",
    "- Dockerfile / Dockercompose pro DB\n",
    "- PDF Datenmodell -> Aufbau von System\n",
    "- Skript / Programm zum Laden von Daten in die DB\n",
    "- Abfragen zum Szenarien\n",
    "- PDF Lessons Learned (`lessons-learned.pdf`)\n",
    "\n",
    "2. DB:\n",
    "- Sollte auf mehrere Container / Knoten laufen\n",
    "  - Wenn es nicht geht, erklären wieso das nicht ging / was dafür gebraucht ist\n",
    "\n",
    "3. App\n",
    "- Laden von Init-Daten\n",
    "- Abfragen feuern\n",
    "- Inhalt anzeigen\n",
    "\n",
    "4. Systemanforderungen\n",
    "- Es gibt:\n",
    "  - Follower-Beziehungen\n",
    "  - Posts von Prominenten\n",
    "- Aufgaben:\n",
    "  - Posts von Prominenten auf die 100 IDs verteilen, die am meisten Follower haben (Influencer)\n",
    "  - Posts können geliked werden (von welchem User wurde ein Post eines anderen Users geliked)\n",
    "    - Zufällig generiert\n",
    "- Anfragen:\n",
    "  - Auflistung von zu einem Account zugeordneten Posts\n",
    "  - Auflistung der 100 Accounts mit den meisten Followern (Influencer)\n",
    "  - Auflistung der 100 Accounts, die den meisten Influencer folgen\n",
    "  - Startseite für ein beliebiges Account (Influencer sind hier gut):\n",
    "    - Anzahl Followers\n",
    "    - Anzahl gefolgte Accounts\n",
    "    - 25 Posts von gefolgten Accounts:\n",
    "      - Neueste\n",
    "      - Meisten Likes\n",
    "    - Caching der Posts für die Startseite\n",
    "    - Auflistung der 25 Posts, die ein Wort beinhalten:\n",
    "      - (Optional: Und-verknüpfte Wörter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d749976",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebee4a9",
   "metadata": {},
   "source": [
    "1. Create conda environment\n",
    "- Create conda environment found in the folder `environment`. \n",
    "- Execute following command: `conda env create -f environment.yml`\n",
    "\n",
    "2. Select conda environment as kernel in notebook\n",
    "3. Start docker containers with docker compose in folder `docker`with `docker-compose up`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b94294",
   "metadata": {},
   "source": [
    "## Install needed libraries and import components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0225325e-4211-49fc-a49a-2c9d1495b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/testenv/lib/python3.9/site-packages (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "from pymongo import MongoClient, InsertOne, UpdateOne\n",
    "from pymongo.errors import ConnectionFailure\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217791b5",
   "metadata": {},
   "source": [
    "## Define the MongoDB server details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c1391a-ffcb-4cb3-ab35-523ce982f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MongoDB server details\n",
    "host = 'localhost'\n",
    "port = 27017\n",
    "username = 'devroot'  # Replace with your MongoDB username\n",
    "password = 'devroot'  # Replace with your MongoDB password\n",
    "\n",
    "# Create the connection string\n",
    "connection_string = f'mongodb://{username}:{password}@{host}:{port}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50eb7b2",
   "metadata": {},
   "source": [
    "## Connect to DB and test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6514139e-fbdf-42cd-941f-357cb92de5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MongoDB server\n",
    "client = MongoClient(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ce421e-7d05-4265-8c5a-78af4bcaebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully to MongoDB\n",
      "Databases: ['admin', 'config', 'local']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Verify connection\n",
    "    client.admin.command('ping')\n",
    "    print(\"Connected successfully to MongoDB\")\n",
    "    \n",
    "    # List all databases\n",
    "    databases = client.list_database_names()\n",
    "    print(\"Databases:\", databases)\n",
    "        \n",
    "except ConnectionFailure as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f25a76",
   "metadata": {},
   "source": [
    "# Global Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d89f52",
   "metadata": {},
   "source": [
    "## Collection definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33419374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the database and collections\n",
    "db = client['social_network']\n",
    "users_collection = db['users']\n",
    "followers_collection = db['followers']\n",
    "posts_collection = db['posts']\n",
    "likes_collection = db['likes']\n",
    "feeds_collection = db['feeds']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fc1bf",
   "metadata": {},
   "source": [
    "## Insertion Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0384ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_followed_users(n):\n",
    "    return users_collection.find().sort(\"followers_count\", -1).limit(n)\n",
    "\n",
    "def add_post_without_likes(user_id, content, date):\n",
    "    post = {\n",
    "        \"user_id\": user_id,\n",
    "        \"content\": content,\n",
    "        \"timestamp\": date,\n",
    "        \"likes\": 0\n",
    "    }\n",
    "    post_id = posts_collection.insert_one(post).inserted_id\n",
    "    return post_id\n",
    "\n",
    "def get_random_users(pool_size, exclude_user_id):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"_id\": {\"$ne\": exclude_user_id}}},\n",
    "        {\"$sample\": {\"size\": pool_size}}\n",
    "    ]\n",
    "    return list(users_collection.aggregate(pipeline))\n",
    "\n",
    "def add_likes_chunk(chunk, random_user_pool):\n",
    "    like_operations = []\n",
    "    like_updates = []\n",
    "\n",
    "    for post_id, user_id, content, date in chunk:\n",
    "        # Generate a random number of likes between 0 and 100\n",
    "        number_of_likes = random.randint(0, 100)\n",
    "        \n",
    "        # Get a random sample of users from the pool\n",
    "        random_users = random.sample(random_user_pool, number_of_likes)\n",
    "        \n",
    "        # Prepare bulk operations for likes\n",
    "        like_operations.extend([\n",
    "            InsertOne({\"userid\": user[\"_id\"], \"postid\": post_id})\n",
    "            for user in random_users\n",
    "        ])\n",
    "\n",
    "        like_updates.append((post_id, number_of_likes))\n",
    "\n",
    "    return like_operations, like_updates\n",
    "\n",
    "def add_likes_bulk(post_data, random_user_pool, max_workers=4):\n",
    "    chunk_size = len(post_data) // max_workers\n",
    "    chunks = [post_data[i:i + chunk_size] for i in range(0, len(post_data), chunk_size)]\n",
    "    \n",
    "    like_operations = []\n",
    "    like_updates = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(add_likes_chunk, chunk, random_user_pool) for chunk in chunks]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing likes\"):\n",
    "            chunk_like_operations, chunk_like_updates = future.result()\n",
    "            like_operations.extend(chunk_like_operations)\n",
    "            like_updates.extend(chunk_like_updates)\n",
    "\n",
    "    if like_operations:\n",
    "        likes_collection.bulk_write(like_operations)\n",
    "\n",
    "    return like_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d4426",
   "metadata": {},
   "source": [
    "## Queries Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103ec1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_with_words(words):\n",
    "    # Construct a list of regex patterns for each word\n",
    "    regex_patterns = [f\"(?=.*\\\\b{word}\\\\b)\" for word in words]\n",
    "    regex_query = {\"content\": {\"$regex\": \"\".join(regex_patterns), \"$options\": \"i\"}}\n",
    "    \n",
    "    # Fetch all posts matching the regex query\n",
    "    posts_cursor = posts_collection.find(regex_query)\n",
    "    posts_list = list(posts_cursor)\n",
    "    posts_count = len(posts_list)\n",
    "    \n",
    "    # Return a dictionary containing both posts and count\n",
    "    result = {\n",
    "        \"posts\": posts_list,\n",
    "        \"count\": posts_count\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "def find_top_users_following_influencers(top_influencers, n):    \n",
    "    # Aggregation pipeline\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"followed_id\": {\"$in\": top_influencers}}},\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$follower_id\",\n",
    "            \"count\": {\"$addToSet\": \"$followed_id\"}\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 1,\n",
    "            \"count\": {\"$size\": \"$count\"}\n",
    "        }},\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\": n}\n",
    "    ]\n",
    "    \n",
    "    # Execute aggregation pipeline and fetch results\n",
    "    cursor = followers_collection.aggregate(pipeline)\n",
    "    \n",
    "    # Convert the cursor to a list to properly handle the results\n",
    "    top_users = list(cursor)\n",
    "    \n",
    "    # Return the result\n",
    "    return top_users\n",
    "\n",
    "def get_user_profile(user_id):\n",
    "    user = users_collection.find_one({\"_id\": user_id})\n",
    "    if not user:\n",
    "        return None  # Handle case where user with user_id doesn't exist\n",
    "    \n",
    "    followers_count = user[\"followers_count\"]\n",
    "    following_count = user[\"following_count\"]\n",
    "\n",
    "    user_posts = list(posts_collection.find({\"user_id\": user_id}))\n",
    "    user_posts_count = len(user_posts)\n",
    "    \n",
    "    user_feed_posts = feeds_collection.find_one({\"user_id\": user_id}).get('posts', [])\n",
    "    user_feed_posts_count = len(user_feed_posts)\n",
    "    \n",
    "    # Sort posts by date\n",
    "    posts_sorted_by_date = sorted(user_feed_posts, key=lambda x: x.get('timestamp', ''), reverse=True)\n",
    "\n",
    "    # Sort posts by likes count\n",
    "    posts_sorted_by_likes = sorted(user_feed_posts, key=lambda x: x.get('likes', 0), reverse=True)\n",
    "    \n",
    "    profile = {\n",
    "        \"user_id\": user_id,\n",
    "        \"followers_count\": followers_count,\n",
    "        \"following_count\": following_count,\n",
    "        \"user_posts\": user_posts,\n",
    "        \"user_posts_count\": user_posts_count,\n",
    "        \"feed\": user_feed_posts,\n",
    "        \"feed_size\": user_feed_posts_count,\n",
    "        \"recent_posts\": posts_sorted_by_date,\n",
    "        \"popular_posts\": posts_sorted_by_likes\n",
    "    }\n",
    "    return profile\n",
    "\n",
    "def print_user_profile(user_profile, n):\n",
    "    print(\"User profile with id:\", user_profile[\"user_id\"])\n",
    "    print(\"Followers count:\", user_profile[\"followers_count\"])\n",
    "    print(\"Following count:\", user_profile[\"following_count\"])\n",
    "    print(\"______________________\\n\")\n",
    "    \n",
    "    print(f\"User posts: ({user_profile['user_posts_count']})\")\n",
    "    for i, post in enumerate(user_profile[\"user_posts\"][:n]):\n",
    "        print(post[\"content\"], \"date:\", post[\"timestamp\"])\n",
    "    print(\"______________________\\n\")\n",
    "    \n",
    "    print(\"Feed (recent):\")\n",
    "    for i, post in enumerate(user_profile[\"recent_posts\"][:n]):\n",
    "        print(post[\"content\"], \"date:\", post[\"timestamp\"])\n",
    "    print(\"______________________\\n\")\n",
    "    \n",
    "    print(\"Feed (popular):\")\n",
    "    for i, post in enumerate(user_profile[\"popular_posts\"][:n]):\n",
    "        print(post[\"content\"], \"likes:\", post.get(\"likes\", \"N/A\"))\n",
    "    print(\"______________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6e6fd",
   "metadata": {},
   "source": [
    "# Insert Data into DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36786a0",
   "metadata": {},
   "source": [
    "## Insert users and following relationships to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a871bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './InputData/twitter_combined.txt'\n",
    "\n",
    "# Read file content\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Prepare data\n",
    "user_pairs = [tuple(map(int, line.strip().split())) for line in lines]\n",
    "\n",
    "# Get a unique set of all users involved\n",
    "all_users = {user for pair in user_pairs for user in pair}\n",
    "\n",
    "# Check which users already exist in the database\n",
    "existing_users = set(users_collection.distinct(\"_id\", {\"_id\": {\"$in\": list(all_users)}}))\n",
    "\n",
    "# Identify new users\n",
    "new_users = all_users - existing_users\n",
    "\n",
    "# Prepare bulk operations for new users\n",
    "user_bulk_operations = [\n",
    "    InsertOne({\"_id\": user_id, \"following_count\": 0, \"followers_count\": 0})\n",
    "    for user_id in new_users\n",
    "]\n",
    "\n",
    "# Execute bulk insert for new users\n",
    "if user_bulk_operations:\n",
    "    users_collection.bulk_write(user_bulk_operations)\n",
    "\n",
    "# Prepare bulk operations for relationships and updating counts\n",
    "relationship_bulk_operations = []\n",
    "user_update_operations = []\n",
    "\n",
    "for user1, user2 in user_pairs:\n",
    "    relationship_bulk_operations.append(InsertOne({\"follower_id\": user1, \"followed_id\": user2}))\n",
    "    user_update_operations.append(UpdateOne({\"_id\": user1}, {\"$inc\": {\"following_count\": 1}}))\n",
    "    user_update_operations.append(UpdateOne({\"_id\": user2}, {\"$inc\": {\"followers_count\": 1}}))\n",
    "\n",
    "# Execute bulk insert for relationships\n",
    "if relationship_bulk_operations:\n",
    "    followers_collection.bulk_write(relationship_bulk_operations)\n",
    "\n",
    "# Execute bulk update for user counts\n",
    "if user_update_operations:\n",
    "    users_collection.bulk_write(user_update_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce03fa",
   "metadata": {},
   "source": [
    "## Assign the input tweets to the influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c303f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting posts: 100%|██████████| 52542/52542 [00:09<00:00, 5530.85it/s]\n"
     ]
    }
   ],
   "source": [
    "top_influencers_list = list(get_most_followed_users(100))\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = './InputData/tweets.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Generate random influencer selections once to avoid repeated random.choice calls\n",
    "influencer_ids = [random.choice(top_influencers_list)['_id'] for _ in range(len(df))]\n",
    "\n",
    "# Function to process each tweet\n",
    "def process_tweet(idx):\n",
    "    tweet_data = df.iloc[idx]\n",
    "    influencer_id = influencer_ids[idx]\n",
    "    date = datetime.strptime(tweet_data['date_time'], '%d/%m/%Y %H:%M')\n",
    "    content = tweet_data['content']\n",
    "    post_id = add_post_without_likes(influencer_id, content, date)\n",
    "    return post_id, influencer_id, content, date\n",
    "\n",
    "# Step 1: Insert all posts first\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    post_data = list(tqdm(executor.map(process_tweet, range(len(df))), total=len(df), desc=\"Inserting posts\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f3338",
   "metadata": {},
   "source": [
    "## Add likes to post randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0940f292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing likes:   0%|          | 0/5 [00:00<?, ?it/s]IOStream.flush timed out\n",
      "Processing likes: 100%|██████████| 5/5 [00:01<00:00,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fetch a pool of random users once\n",
    "user_pool_size = 10000  # Adjust the pool size as needed\n",
    "random_user_pool = get_random_users(user_pool_size, exclude_user_id=None)\n",
    "\n",
    "# Step 2: Insert likes for posts in bulk\n",
    "like_updates = add_likes_bulk(post_data, random_user_pool, max_workers=4)\n",
    "\n",
    "# Step 3: Update post like counts in bulk\n",
    "bulk_updates = [\n",
    "    UpdateOne({\"_id\": post_id}, {\"$set\": {\"likes\": likes}})\n",
    "    for post_id, likes in like_updates\n",
    "]\n",
    "if bulk_updates:\n",
    "    posts_collection.bulk_write(bulk_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4c4b0",
   "metadata": {},
   "source": [
    "## Add indices to collection when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d221ec84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user_id_1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add indices to critical parameters on collections\n",
    "followers_collection.create_index([(\"followed_id\", 1), (\"follower_id\", 1)])\n",
    "\n",
    "posts_collection.create_index([(\"user_id\", 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40510e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 53/53 [06:59<00:00,  7.92s/it]\n",
      "Processing Temp Feeds: 100%|██████████| 28102/28102 [02:32<00:00, 183.94it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_feeds_collection = db['temp_feeds']\n",
    "\n",
    "batch_size = 1000  # Define a suitable batch size\n",
    "post_count = posts_collection.count_documents({})\n",
    "num_batches = (post_count // batch_size) + 1\n",
    "\n",
    "# Step 1: Aggregate data into a temporary collection\n",
    "for batch in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "    pipeline = [\n",
    "        {\"$skip\": batch * batch_size},\n",
    "        {\"$limit\": batch_size},\n",
    "        {\"$lookup\": {\n",
    "            \"from\": \"followers\",\n",
    "            \"localField\": \"user_id\",\n",
    "            \"foreignField\": \"followed_id\",\n",
    "            \"as\": \"followers\"\n",
    "        }},\n",
    "        {\"$unwind\": \"$followers\"},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"follower_id\": \"$followers.follower_id\",\n",
    "            \"post\": {\n",
    "                \"post_id\": \"$_id\",\n",
    "                \"user_id\": \"$user_id\",\n",
    "                \"content\": \"$content\",\n",
    "                \"timestamp\": \"$timestamp\",\n",
    "                \"likes\": \"$likes\"\n",
    "            }\n",
    "        }},\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$follower_id\",\n",
    "            \"posts\": {\"$push\": \"$post\"}\n",
    "        }},\n",
    "        {\"$out\": \"temp_feeds\"}\n",
    "    ]\n",
    "    posts_collection.aggregate(pipeline)\n",
    "\n",
    "# Step 2: Process the temporary collection to split large documents\n",
    "temp_docs = list(temp_feeds_collection.find())\n",
    "for doc in tqdm(temp_docs, desc=\"Processing Temp Feeds\"):\n",
    "    follower_id = doc['_id']\n",
    "    posts = doc['posts']\n",
    "    \n",
    "    chunk_size = 100\n",
    "    chunked_posts = [posts[i:i + chunk_size] for i in range(0, len(posts), chunk_size)]\n",
    "    \n",
    "    for chunk in chunked_posts:\n",
    "        feeds_collection.update_one(\n",
    "            {\"user_id\": follower_id},\n",
    "            {\"$push\": {\"posts\": {\"$each\": chunk}}},\n",
    "            upsert=True\n",
    "        )\n",
    "\n",
    "# Step 3: Ensure posts arrays are unique and in order\n",
    "# Use aggregation pipeline to deduplicate and sort posts\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"unique_posts\": {\"$setUnion\": \"$posts\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"user_id\": 1,\n",
    "            \"posts\": {\"$slice\": [{\"$sortArray\": {\"input\": \"$unique_posts\", \"sortBy\": {\"timestamp\": -1}}}, 16793600]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$merge\": {\n",
    "            \"into\": \"feeds\",\n",
    "            \"whenMatched\": \"replace\",\n",
    "            \"whenNotMatched\": \"insert\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "feeds_collection.aggregate(pipeline)\n",
    "\n",
    "# Clean up temporary collection\n",
    "temp_feeds_collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b99cb",
   "metadata": {},
   "source": [
    "# Request data from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89939c93",
   "metadata": {},
   "source": [
    "## Find out top 100 most followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120be840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top influencers:\n",
      "user id: 40981798 Follower count 8660\n",
      "user id: 43003845 Follower count 7700\n",
      "user id: 22462180 Follower count 7623\n",
      "user id: 34428380 Follower count 7558\n",
      "user id: 115485051 Follower count 4798\n",
      "user id: 15913 Follower count 4337\n",
      "user id: 3359851 Follower count 3986\n",
      "user id: 11348282 Follower count 3850\n",
      "user id: 7861312 Follower count 3712\n",
      "user id: 27633075 Follower count 3655\n",
      "user id: 31331740 Follower count 3623\n",
      "user id: 18996905 Follower count 3255\n",
      "user id: 7860742 Follower count 3197\n",
      "user id: 813286 Follower count 3172\n",
      "user id: 22784458 Follower count 2974\n",
      "user id: 17868918 Follower count 2904\n",
      "user id: 10671602 Follower count 2874\n",
      "user id: 117674417 Follower count 2858\n",
      "user id: 48485771 Follower count 2725\n",
      "user id: 34068984 Follower count 2693\n",
      "user id: 18927441 Follower count 2680\n",
      "user id: 83943787 Follower count 2678\n",
      "user id: 15853668 Follower count 2634\n",
      "user id: 1183041 Follower count 2593\n",
      "user id: 238260874 Follower count 2560\n",
      "user id: 8088112 Follower count 2539\n",
      "user id: 16464746 Follower count 2425\n",
      "user id: 16098603 Follower count 2399\n",
      "user id: 88323281 Follower count 2356\n",
      "user id: 18776017 Follower count 2346\n",
      "user id: 133055665 Follower count 2342\n",
      "user id: 263838766 Follower count 2317\n",
      "user id: 309366491 Follower count 2291\n",
      "user id: 90420314 Follower count 2241\n",
      "user id: 116036694 Follower count 2238\n",
      "user id: 31353077 Follower count 2209\n",
      "user id: 100318079 Follower count 2208\n",
      "user id: 14654965 Follower count 2122\n",
      "user id: 63485337 Follower count 2095\n",
      "user id: 59804598 Follower count 2083\n",
      "user id: 10350 Follower count 2073\n",
      "user id: 195475105 Follower count 2069\n",
      "user id: 16303106 Follower count 2031\n",
      "user id: 270449528 Follower count 2014\n",
      "user id: 151338729 Follower count 1981\n",
      "user id: 19358562 Follower count 1927\n",
      "user id: 24742040 Follower count 1897\n",
      "user id: 65913144 Follower count 1862\n",
      "user id: 26281970 Follower count 1821\n",
      "user id: 116952434 Follower count 1799\n",
      "user id: 30313925 Follower count 1775\n",
      "user id: 187773078 Follower count 1774\n",
      "user id: 5442012 Follower count 1763\n",
      "user id: 15234657 Follower count 1752\n",
      "user id: 79797834 Follower count 1742\n",
      "user id: 276706356 Follower count 1725\n",
      "user id: 16475194 Follower count 1718\n",
      "user id: 280935165 Follower count 1710\n",
      "user id: 27855118 Follower count 1696\n",
      "user id: 204317520 Follower count 1674\n",
      "user id: 121533789 Follower count 1668\n",
      "user id: 69592091 Follower count 1665\n",
      "user id: 82030021 Follower count 1657\n",
      "user id: 28465635 Follower count 1656\n",
      "user id: 18742444 Follower count 1625\n",
      "user id: 254839786 Follower count 1600\n",
      "user id: 972651 Follower count 1591\n",
      "user id: 47787563 Follower count 1568\n",
      "user id: 7872262 Follower count 1567\n",
      "user id: 14075928 Follower count 1559\n",
      "user id: 783214 Follower count 1550\n",
      "user id: 19040580 Follower count 1536\n",
      "user id: 14922225 Follower count 1529\n",
      "user id: 26929220 Follower count 1528\n",
      "user id: 284422688 Follower count 1524\n",
      "user id: 204140367 Follower count 1520\n",
      "user id: 93905958 Follower count 1496\n",
      "user id: 46423291 Follower count 1493\n",
      "user id: 19493072 Follower count 1491\n",
      "user id: 19802879 Follower count 1480\n",
      "user id: 21681252 Follower count 1479\n",
      "user id: 314316607 Follower count 1479\n",
      "user id: 14230524 Follower count 1472\n",
      "user id: 11928542 Follower count 1467\n",
      "user id: 428333 Follower count 1439\n",
      "user id: 24585498 Follower count 1437\n",
      "user id: 19725644 Follower count 1426\n",
      "user id: 22679419 Follower count 1411\n",
      "user id: 2367911 Follower count 1406\n",
      "user id: 17093617 Follower count 1405\n",
      "user id: 62581962 Follower count 1402\n",
      "user id: 17224642 Follower count 1399\n",
      "user id: 149538028 Follower count 1396\n",
      "user id: 15439395 Follower count 1395\n",
      "user id: 259842341 Follower count 1391\n",
      "user id: 173732041 Follower count 1385\n",
      "user id: 47161442 Follower count 1381\n",
      "user id: 153226312 Follower count 1378\n",
      "user id: 131601987 Follower count 1372\n",
      "user id: 229039814 Follower count 1370\n"
     ]
    }
   ],
   "source": [
    "# Get and print top influencers\n",
    "top_influencers = get_most_followed_users(100)\n",
    "print(\"Top influencers:\")\n",
    "top_influencers_id_list = []\n",
    "for influencer in top_influencers:\n",
    "    print(\"user id:\", influencer[\"_id\"], \"Follower count\", influencer[\"followers_count\"])\n",
    "    top_influencers_id_list.append(influencer[\"_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1dc4ba",
   "metadata": {},
   "source": [
    "## Find out top 100 influencer followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9659e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: User ID 3359851 follows 51 influencers\n",
      "#2: User ID 24641194 follows 43 influencers\n",
      "#3: User ID 18581803 follows 42 influencers\n",
      "#4: User ID 440963134 follows 40 influencers\n",
      "#5: User ID 7872262 follows 40 influencers\n",
      "#6: User ID 364917755 follows 40 influencers\n",
      "#7: User ID 274153775 follows 39 influencers\n",
      "#8: User ID 401313910 follows 38 influencers\n",
      "#9: User ID 463952369 follows 38 influencers\n",
      "#10: User ID 358775055 follows 38 influencers\n",
      "#11: User ID 439788025 follows 38 influencers\n",
      "#12: User ID 277649366 follows 38 influencers\n",
      "#13: User ID 134940306 follows 38 influencers\n",
      "#14: User ID 279787626 follows 38 influencers\n",
      "#15: User ID 46209291 follows 38 influencers\n",
      "#16: User ID 135218281 follows 38 influencers\n",
      "#17: User ID 208132323 follows 38 influencers\n",
      "#18: User ID 77618627 follows 37 influencers\n",
      "#19: User ID 278652553 follows 37 influencers\n",
      "#20: User ID 430182387 follows 37 influencers\n",
      "#21: User ID 259842341 follows 37 influencers\n",
      "#22: User ID 157829215 follows 37 influencers\n",
      "#23: User ID 307458983 follows 37 influencers\n",
      "#24: User ID 94414805 follows 37 influencers\n",
      "#25: User ID 304462046 follows 37 influencers\n",
      "#26: User ID 14691709 follows 37 influencers\n",
      "#27: User ID 7860742 follows 37 influencers\n",
      "#28: User ID 276308596 follows 37 influencers\n",
      "#29: User ID 430268163 follows 37 influencers\n",
      "#30: User ID 461410856 follows 37 influencers\n",
      "#31: User ID 440341213 follows 37 influencers\n",
      "#32: User ID 236184723 follows 37 influencers\n",
      "#33: User ID 18776017 follows 37 influencers\n",
      "#34: User ID 280935165 follows 36 influencers\n",
      "#35: User ID 451250774 follows 36 influencers\n",
      "#36: User ID 14573745 follows 36 influencers\n",
      "#37: User ID 100581193 follows 36 influencers\n",
      "#38: User ID 208549187 follows 36 influencers\n",
      "#39: User ID 16098603 follows 36 influencers\n",
      "#40: User ID 308723182 follows 36 influencers\n",
      "#41: User ID 214328887 follows 36 influencers\n",
      "#42: User ID 479854996 follows 36 influencers\n",
      "#43: User ID 317076339 follows 36 influencers\n",
      "#44: User ID 153226312 follows 36 influencers\n",
      "#45: User ID 270449528 follows 36 influencers\n",
      "#46: User ID 216088014 follows 36 influencers\n",
      "#47: User ID 395559648 follows 36 influencers\n",
      "#48: User ID 103598216 follows 35 influencers\n",
      "#49: User ID 224309765 follows 35 influencers\n",
      "#50: User ID 545020142 follows 35 influencers\n",
      "#51: User ID 387237264 follows 35 influencers\n",
      "#52: User ID 204140367 follows 35 influencers\n",
      "#53: User ID 22841103 follows 35 influencers\n",
      "#54: User ID 195475105 follows 35 influencers\n",
      "#55: User ID 57490887 follows 35 influencers\n",
      "#56: User ID 254839786 follows 35 influencers\n",
      "#57: User ID 280365428 follows 35 influencers\n",
      "#58: User ID 14269220 follows 35 influencers\n",
      "#59: User ID 318434640 follows 35 influencers\n",
      "#60: User ID 56860418 follows 35 influencers\n",
      "#61: User ID 480083825 follows 35 influencers\n",
      "#62: User ID 123371682 follows 35 influencers\n",
      "#63: User ID 235978600 follows 34 influencers\n",
      "#64: User ID 24081780 follows 34 influencers\n",
      "#65: User ID 389742937 follows 34 influencers\n",
      "#66: User ID 302847930 follows 34 influencers\n",
      "#67: User ID 107830991 follows 34 influencers\n",
      "#68: User ID 15846407 follows 34 influencers\n",
      "#69: User ID 160237722 follows 34 influencers\n",
      "#70: User ID 67864340 follows 34 influencers\n",
      "#71: User ID 100318079 follows 34 influencers\n",
      "#72: User ID 8470732 follows 34 influencers\n",
      "#73: User ID 285359479 follows 34 influencers\n",
      "#74: User ID 145129229 follows 34 influencers\n",
      "#75: User ID 314316607 follows 34 influencers\n",
      "#76: User ID 196680777 follows 34 influencers\n",
      "#77: User ID 496438192 follows 34 influencers\n",
      "#78: User ID 328590469 follows 34 influencers\n",
      "#79: User ID 197504076 follows 34 influencers\n",
      "#80: User ID 406628822 follows 33 influencers\n",
      "#81: User ID 493102437 follows 33 influencers\n",
      "#82: User ID 144631425 follows 33 influencers\n",
      "#83: User ID 26929220 follows 33 influencers\n",
      "#84: User ID 230880104 follows 33 influencers\n",
      "#85: User ID 523885474 follows 33 influencers\n",
      "#86: User ID 83943787 follows 33 influencers\n",
      "#87: User ID 204317520 follows 33 influencers\n",
      "#88: User ID 7846 follows 33 influencers\n",
      "#89: User ID 217796457 follows 33 influencers\n",
      "#90: User ID 72818790 follows 33 influencers\n",
      "#91: User ID 65913144 follows 32 influencers\n",
      "#92: User ID 17759701 follows 32 influencers\n",
      "#93: User ID 116952434 follows 32 influencers\n",
      "#94: User ID 14536491 follows 32 influencers\n",
      "#95: User ID 116036694 follows 32 influencers\n",
      "#96: User ID 232818548 follows 32 influencers\n",
      "#97: User ID 5442012 follows 32 influencers\n",
      "#98: User ID 151495845 follows 32 influencers\n",
      "#99: User ID 222261763 follows 32 influencers\n",
      "#100: User ID 267425413 follows 32 influencers\n"
     ]
    }
   ],
   "source": [
    "top_influencer_followers = find_top_users_following_influencers(top_influencers_id_list, 100)\n",
    "\n",
    "# Print the top users\n",
    "for i, doc in enumerate(top_influencer_followers):\n",
    "    print(f\"#{i+1}: User ID {doc['_id']} follows {doc['count']} influencers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce50c0f",
   "metadata": {},
   "source": [
    "## Show user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d36a084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User profile with id: 22462180\n",
      "Followers count: 7623\n",
      "Following count: 701\n",
      "______________________\n",
      "\n",
      "User posts: (507)\n",
      "@katyperryforum I'm Kanye date: 2016-10-25 08:27:00\n",
      "tap it if you're nasty @ UNLV Campus https://t.co/vDHH4kAVLO date: 2016-10-23 07:13:00\n",
      "I love when everything starts to align for transformation time...✨ date: 2016-10-21 22:52:00\n",
      ". @ferras &amp; I are cadence kweens 👑 cc @jessesaintjohn date: 2016-10-05 06:51:00\n",
      "@prismdluxe ur right I've had too much truth tea this morn date: 2016-09-10 21:25:00\n",
      "EXCLUSIVE! Unlock the #KatyKatHouse for brand new vids &amp; more from me, @COVERGIRL, &amp; the Katy Kat Collection! https://t.co/90z6YGdgbD date: 2016-07-25 16:01:00\n",
      "@wakingonair @drwssinup u guys are the examples ❗️ date: 2016-07-23 06:07:00\n",
      "Ish, It's in the definition babe https://t.co/4foqulMj3v date: 2016-07-15 05:33:00\n",
      "🇺🇸📢✍🏻Every voice is important &amp; every vote counts. No matter where you stand, register to vote!✍🏻📢🇺🇸 #RockTheVote https://t.co/ROj1MnMHZE date: 2016-05-23 17:07:00\n",
      "@kendricklamar THAT WAS SO POWERFUL. date: 2016-02-16 03:51:00\n",
      "Thx @CBS 4 including our lil pas de bourree on the list of Greatest Super Bowl Halftimes! Kick off 🏈wknd 2night @ 9! https://t.co/xPyurX01uo date: 2016-02-06 00:11:00\n",
      "...and in the reality of the music industry, you must have talent first and foremost. #AppStoreChat date: 2015-12-18 22:32:00\n",
      "...record label has helped write this storyline, but at the end of the day, this is not a talent-based game, it's a skill-based game... date: 2015-12-18 22:31:00\n",
      "#Repost hillaryclinton \n",
      "👆 #ImWithHer -Katy https://t.co/2ZJMYrWi9c date: 2015-10-24 23:46:00\n",
      "T-MINUS 3 HOURS until #PrismaticOnEpix! Tune in at 8p ET on @EpixHD or stream it on http://t.co/fPliCOE8vi! date: 2015-03-28 21:01:00\n",
      "Shanghai! So pleased to be able to play for you twice! Tickets on sale Mar 10 @ 2:00p. See you April 21st &amp; NOW 22nd! http://t.co/l3WgZjvojk date: 2015-03-05 02:04:00\n",
      "Because: 🏈 http://t.co/zHNs52PTFa date: 2015-01-30 06:41:00\n",
      "I'M HEADLINING ROCK IN RIO NEXT SEPTEMBER!!! Keep your 👀 peeled for more info, coming soon! #RockInRio date: 2014-09-26 22:35:00\n",
      "Noticed and noted bb “@PerrysTiger: @katyperry #THISISHOWWEDO PLEASE NOTICE ME :) http://t.co/zoGr5Rx8CW” date: 2014-08-11 19:51:00\n",
      "So...I have a HUGE announcement I finally get to share with you tomorrow... Stay tuned... date: 2014-06-17 03:16:00\n",
      "Got vacation braids, don't be jelly date: 2014-06-07 23:05:00\n",
      "🎉FOR HIRE🎉 http://t.co/YKd29Fb5ir date: 2014-04-23 20:02:00\n",
      "In other non related Bieber news, a spectacular BOOK (these things have more than 140 characters) is coming out SOON: http://t.co/WL2WzvsB6O date: 2014-01-23 23:05:00\n",
      "My Brazilian babies!!! “@beatforkaty: @katyperry I JUST BOUGHT, ARE YOU PROUD? 5 http://t.co/qH5S7bXhDa” date: 2013-08-25 05:13:00\n",
      "I spy something long and gold in Las Vegas tonight... #PRISM date: 2013-08-01 05:16:00\n",
      "______________________\n",
      "\n",
      "Feed (recent):\n",
      "It's midnight... Officially #CoolForTheSummerDay 🍒🍒🍒🍒🍒 get it in just 7 or 8 hours!!!!!!!! #COOLFORTHESUMMER date: 2015-07-01 04:06:00\n",
      "#CoolForTheSummer 4 DAYS 😎 http://t.co/FfoZoScipy date: 2015-06-27 21:41:00\n",
      "Hey guys.. Don't be lame for the summer and take pics paparazzi style on your phone... 🍉🍒☀️🌴 be #CoolForTheSummer and just say hi 😊 date: 2015-06-27 04:50:00\n",
      "#LOVEWINS 🌈💗💚💜💛💙 https://t.co/bdvdGFM6Nq date: 2015-06-27 00:59:00\n",
      "SO proud of my best friend @m_callahan starting her blog which has grown so fast so soon... http://t.co/tdKAgBpb1B!!! date: 2015-06-11 15:46:00\n",
      "Best security guard out there.... 😜 https://t.co/vcX6xjKkTb date: 2015-06-08 08:43:00\n",
      "I do not understand why TSA agents have to be so rude sometimes. It's 7:30 am... How do you even have the energy to be negative this early? date: 2015-06-07 11:33:00\n",
      "This. 😭😭😭👏🏼👏🏼👏🏼 https://t.co/HuBAyWMCth date: 2015-06-02 02:32:00\n",
      "Ugghhhh I wish I could post pictures from last weeks shoot.... I'm DYING to!!! So excited for yall to see them 😊 date: 2015-06-01 00:06:00\n",
      "I love life 💗 date: 2015-06-01 00:00:00\n",
      "Thanks @Tony__Aguilar!! See you at #cocacolamusicexperience, the 16th of October!!! @CocaCola_es ❤️❤️ date: 2015-05-31 18:01:00\n",
      "Help 😭 https://t.co/nMAxgOWHCb date: 2015-05-27 11:37:00\n",
      "Last but not least... Phil McIntyre. This man not only believed in me when I was 15 and made my… https://t.co/sR3fIudJYm date: 2015-05-27 04:04:00\n",
      "Very grateful for this man... Ladies and gentlemen.. David Massey!! Finally we can post a pic… https://t.co/sdZ95KnsSS date: 2015-05-27 03:27:00\n",
      "🎶 This workout's gonna hurt like a motherfuckaaaa.... 🎶 #remix date: 2015-05-24 06:01:00\n",
      "25lb. planks 💪🏼😎 https://t.co/5UmC2FfZkM date: 2015-05-24 02:38:00\n",
      "I've literally been asleep for the past 48 hours........ I guess I needed it??? 😳 date: 2015-05-23 15:28:00\n",
      "@tonyromo retweeted my mom and now she thinks he loves her...... 😑 @redraider30... You better get back home!!!!! date: 2015-05-21 04:42:00\n",
      "Did yall hear my thoughts on #NMM?? Tell me what you think..... 🚫💄❤️ #naturalbeauty  #devonnebydemi https://t.co/S0pkcqvCu4 date: 2015-05-20 14:08:00\n",
      "Yesterday I was working so hard in the studio I missed my #NMM picture!!! So here it is!! 😝… https://t.co/H1FSqS750u date: 2015-05-19 16:57:00\n",
      "Great job @nickjonas 👏🏼👏🏼👏🏼 date: 2015-05-18 05:39:00\n",
      "I 💗 China and everyone on this tour!! #demiworldtour https://t.co/YlVK7RYbcJ date: 2015-05-04 08:01:00\n",
      "Goodbye New Zealand.... You were incredible and absolutely beautiful. ✌️#demiworldtour https://t.co/KM0kZbcjo0 date: 2015-04-26 12:14:00\n",
      "Had to 😳😍 http://t.co/mcllGsnHxI date: 2015-04-24 15:17:00\n",
      "Success comes when you realize you want it more than sleep date: 2015-04-07 17:11:00\n",
      "______________________\n",
      "\n",
      "Feed (popular):\n",
      "GUYS.... WE HAVE CANDLES!!!!! 😱😱😱💜💜💜 #DevonneByDemi http://t.co/PfGJMeuO0t http://t.co/lce0dTVWy2 likes: 100\n",
      "Success comes when you realize you want it more than sleep likes: 94\n",
      "I'm so grateful for the women in my life. I truly am blessed.. likes: 93\n",
      "When bae puts you in a onesie....... 😳 https://t.co/7r3KrZ2WQi likes: 92\n",
      "I ❤️ NY https://t.co/UIjyakS78g likes: 92\n",
      "Sooo many freckles!! 😝 https://t.co/ecOH5fa9nI likes: 91\n",
      "Answered some questions about nip slips and aliens in the @LovatoClub here: http://t.co/sG9LILLvpR 😜👽\n",
      "https://t.co/4W8GP4XDOg likes: 91\n",
      "Did yall hear my thoughts on #NMM?? Tell me what you think..... 🚫💄❤️ #naturalbeauty  #devonnebydemi https://t.co/S0pkcqvCu4 likes: 90\n",
      "Best security guard out there.... 😜 https://t.co/vcX6xjKkTb likes: 89\n",
      "Exclusive new video from @devonnebydemi!!! For the full length video go to http://t.co/PfGJMflBoF :) #DevonneByDemi\n",
      "https://t.co/8Q2doszB9P likes: 88\n",
      "Good fight, poor sportsmanship. Shake hands guys.. Grow up!!! #ufc likes: 86\n",
      "Tickets on sale tomorrow at 5pm PST at http://t.co/W0Trpda3iq!!! likes: 83\n",
      "SO proud of my best friend @m_callahan starting her blog which has grown so fast so soon... http://t.co/tdKAgBpb1B!!! likes: 75\n",
      "25lb. planks 💪🏼😎 https://t.co/5UmC2FfZkM likes: 75\n",
      "Goodbye New Zealand.... You were incredible and absolutely beautiful. ✌️#demiworldtour https://t.co/KM0kZbcjo0 likes: 74\n",
      "So proud of this girl- @beamiller’s debut album is available for pre-order today!! Go get it!! http://t.co/ILw60ttzHv http://t.co/0xeGe6xfc2 likes: 70\n",
      "I love life 💗 likes: 69\n",
      "That motherfucker..... Whoop him Silva likes: 67\n",
      "It's midnight... Officially #CoolForTheSummerDay 🍒🍒🍒🍒🍒 get it in just 7 or 8 hours!!!!!!!! #COOLFORTHESUMMER likes: 64\n",
      "Ugghhhh I wish I could post pictures from last weeks shoot.... I'm DYING to!!! So excited for yall to see them 😊 likes: 64\n",
      "Buddy has me up at 7 am on the dot every morning. I am officially a morning person!! #goodmorning ☀️☕️😊 likes: 63\n",
      "It's so easy! 💁 @mysecretcolor http://t.co/LZ8v8sXet0\n",
      "https://t.co/FJpNiC4dwX likes: 58\n",
      "#CoolForTheSummer 4 DAYS 😎 http://t.co/FfoZoScipy likes: 57\n",
      "I do not understand why TSA agents have to be so rude sometimes. It's 7:30 am... How do you even have the energy to be negative this early? likes: 57\n",
      "Help 😭 https://t.co/nMAxgOWHCb likes: 56\n",
      "______________________\n"
     ]
    }
   ],
   "source": [
    "# Get and print user profile\n",
    "user_id = 22462180\n",
    "tweets_to_show = 25\n",
    "user_profile = get_user_profile(user_id)\n",
    "print_user_profile(user_profile, tweets_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8ab90",
   "metadata": {},
   "source": [
    "## Posts containing word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96124357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 2\n",
      "Post content: Several @twittereng folks teamed up with @UCBerkeley for a course about analyzing big data: @UCBTweeter. http://t.co/5SUkxQJr\n",
      "Post content: Twitter + the Human Face of Big Data: http://t.co/HlpWw7rV @faceofbigdata #HFOBD / #BigDataChat 11am PT/2pm ET Friday 10/19 w/@isaach\n"
     ]
    }
   ],
   "source": [
    "#words_to_search = [\"alejandro\", \"sexy\"]\n",
    "words_to_search = [\"big\", \"data\"]\n",
    "result = get_posts_with_words(words_to_search)\n",
    "\n",
    "# Print the count of posts found\n",
    "print(\"Number of posts:\", result[\"count\"])\n",
    "\n",
    "# Iterate over and print each post content\n",
    "for post in result[\"posts\"]:\n",
    "    print(\"Post content:\", post[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed336184",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb94af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users_collection.drop()\n",
    "# followers_collection.drop()\n",
    "# posts_collection.drop()\n",
    "# likes_collection.drop()\n",
    "# feeds_collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cf83358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
