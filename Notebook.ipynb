{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d749976",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebee4a9",
   "metadata": {},
   "source": [
    "1. Create conda environment\n",
    "- Create conda environment found in the folder `environment`. \n",
    "- Execute following command: `conda env create -f environment.yml`\n",
    "\n",
    "2. Select conda environment as kernel in notebook\n",
    "3. Start docker containers with docker compose in folder `docker`with `docker-compose up`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b94294",
   "metadata": {},
   "source": [
    "## Install needed libraries and import components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0225325e-4211-49fc-a49a-2c9d1495b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/testenv/lib/python3.9/site-packages (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "from pymongo import MongoClient, InsertOne, UpdateOne\n",
    "from pymongo.errors import ConnectionFailure\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217791b5",
   "metadata": {},
   "source": [
    "## Define the MongoDB server details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9c1391a-ffcb-4cb3-ab35-523ce982f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MongoDB server details\n",
    "host = 'localhost'\n",
    "port = 27017\n",
    "username = 'devroot'  # Replace with your MongoDB username\n",
    "password = 'devroot'  # Replace with your MongoDB password\n",
    "\n",
    "# Define the MongoDB server details\n",
    "port2 = 27018\n",
    "\n",
    "# Create the connection string\n",
    "connection_string = f'mongodb://{username}:{password}@{host}:{port}'\n",
    "connection_string2 = f'mongodb://{username}:{password}@{host}:{port2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50eb7b2",
   "metadata": {},
   "source": [
    "## Connect to DB and test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6514139e-fbdf-42cd-941f-357cb92de5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MongoDB server\n",
    "client = MongoClient(connection_string)\n",
    "\n",
    "# Connect to the MongoDB server\n",
    "client2 = MongoClient(connection_string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ce421e-7d05-4265-8c5a-78af4bcaebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully to MongoDB\n",
      "Databases: ['admin', 'config', 'local', 'social_network']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Verify connection\n",
    "    client.admin.command('ping')\n",
    "    print(\"Connected successfully to MongoDB\")\n",
    "    \n",
    "    # List all databases\n",
    "    databases = client.list_database_names()\n",
    "    print(\"Databases:\", databases)\n",
    "        \n",
    "except ConnectionFailure as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3370fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully to MongoDB\n",
      "Databases: ['admin', 'config', 'local']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Verify connection\n",
    "    client2.admin.command('ping')\n",
    "    print(\"Connected successfully to MongoDB\")\n",
    "    \n",
    "    # List all databases\n",
    "    databases = client2.list_database_names()\n",
    "    print(\"Databases:\", databases)\n",
    "        \n",
    "except ConnectionFailure as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f25a76",
   "metadata": {},
   "source": [
    "# Global Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d89f52",
   "metadata": {},
   "source": [
    "## Collection definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33419374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the database and collections\n",
    "db = client['social_network']\n",
    "db2 = client2['social_network2']\n",
    "\n",
    "users_collection = db['users']\n",
    "followers_collection = db['followers']\n",
    "posts_collection = db['posts']\n",
    "likes_collection = db2['likes']\n",
    "feeds_collection = db['feeds']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fc1bf",
   "metadata": {},
   "source": [
    "## Insertion Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0384ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_followed_users(n):\n",
    "    return users_collection.find().sort(\"followers_count\", -1).limit(n)\n",
    "\n",
    "def add_post_without_likes(user_id, content, date):\n",
    "    post = {\n",
    "        \"user_id\": user_id,\n",
    "        \"content\": content,\n",
    "        \"timestamp\": date,\n",
    "        \"likes\": 0\n",
    "    }\n",
    "    post_id = posts_collection.insert_one(post).inserted_id\n",
    "    return post_id\n",
    "\n",
    "def get_random_users(pool_size, exclude_user_id):\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"_id\": {\"$ne\": exclude_user_id}}},\n",
    "        {\"$sample\": {\"size\": pool_size}}\n",
    "    ]\n",
    "    return list(users_collection.aggregate(pipeline))\n",
    "\n",
    "def add_likes_chunk(chunk, random_user_pool):\n",
    "    like_operations = []\n",
    "    like_updates = []\n",
    "\n",
    "    for post_id, user_id, content, date in chunk:\n",
    "        # Generate a random number of likes between 0 and 100\n",
    "        number_of_likes = random.randint(0, 100)\n",
    "        \n",
    "        # Get a random sample of users from the pool\n",
    "        random_users = random.sample(random_user_pool, number_of_likes)\n",
    "        \n",
    "        # Prepare bulk operations for likes\n",
    "        like_operations.extend([\n",
    "            InsertOne({\"userid\": user[\"_id\"], \"postid\": post_id})\n",
    "            for user in random_users\n",
    "        ])\n",
    "\n",
    "        like_updates.append((post_id, number_of_likes))\n",
    "\n",
    "    return like_operations, like_updates\n",
    "\n",
    "def add_likes_bulk(post_data, random_user_pool, max_workers=4):\n",
    "    chunk_size = len(post_data) // max_workers\n",
    "    chunks = [post_data[i:i + chunk_size] for i in range(0, len(post_data), chunk_size)]\n",
    "    \n",
    "    like_operations = []\n",
    "    like_updates = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(add_likes_chunk, chunk, random_user_pool) for chunk in chunks]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing likes\"):\n",
    "            chunk_like_operations, chunk_like_updates = future.result()\n",
    "            like_operations.extend(chunk_like_operations)\n",
    "            like_updates.extend(chunk_like_updates)\n",
    "\n",
    "    if like_operations:\n",
    "        likes_collection.bulk_write(like_operations)\n",
    "\n",
    "    return like_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d4426",
   "metadata": {},
   "source": [
    "## Queries Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103ec1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_with_words(words):\n",
    "    # Construct a list of regex patterns for each word\n",
    "    regex_patterns = [f\"(?=.*\\\\b{word}\\\\b)\" for word in words]\n",
    "    regex_query = {\"content\": {\"$regex\": \"\".join(regex_patterns), \"$options\": \"i\"}}\n",
    "    \n",
    "    # Fetch all posts matching the regex query\n",
    "    posts_cursor = posts_collection.find(regex_query)\n",
    "    posts_list = list(posts_cursor)\n",
    "    posts_count = len(posts_list)\n",
    "    \n",
    "    # Return a dictionary containing both posts and count\n",
    "    result = {\n",
    "        \"posts\": posts_list,\n",
    "        \"count\": posts_count\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "def find_top_users_following_influencers(top_influencers, n):    \n",
    "    # Aggregation pipeline\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"followed_id\": {\"$in\": top_influencers}}},\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$follower_id\",\n",
    "            \"count\": {\"$addToSet\": \"$followed_id\"}\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 1,\n",
    "            \"count\": {\"$size\": \"$count\"}\n",
    "        }},\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\": n}\n",
    "    ]\n",
    "    \n",
    "    # Execute aggregation pipeline and fetch results\n",
    "    cursor = followers_collection.aggregate(pipeline)\n",
    "    \n",
    "    # Convert the cursor to a list to properly handle the results\n",
    "    top_users = list(cursor)\n",
    "    \n",
    "    # Return the result\n",
    "    return top_users\n",
    "\n",
    "def get_user_profile(user_id):\n",
    "    user = users_collection.find_one({\"_id\": user_id})\n",
    "    if not user:\n",
    "        return None  # Handle case where user with user_id doesn't exist\n",
    "    \n",
    "    followers_count = user[\"followers_count\"]\n",
    "    following_count = user[\"following_count\"]\n",
    "\n",
    "    user_posts = list(posts_collection.find({\"user_id\": user_id}))\n",
    "    user_posts_count = len(user_posts)\n",
    "    \n",
    "    user_feed_posts = feeds_collection.find_one({\"user_id\": user_id}).get('posts', [])\n",
    "    user_feed_posts_count = len(user_feed_posts)\n",
    "    \n",
    "    # Sort posts by date\n",
    "    posts_sorted_by_date = sorted(user_feed_posts, key=lambda x: x.get('timestamp', ''), reverse=True)\n",
    "\n",
    "    # Sort posts by likes count\n",
    "    posts_sorted_by_likes = sorted(user_feed_posts, key=lambda x: x.get('likes', 0), reverse=True)\n",
    "    \n",
    "    profile = {\n",
    "        \"user_id\": user_id,\n",
    "        \"followers_count\": followers_count,\n",
    "        \"following_count\": following_count,\n",
    "        \"user_posts\": user_posts,\n",
    "        \"user_posts_count\": user_posts_count,\n",
    "        \"feed\": user_feed_posts,\n",
    "        \"feed_size\": user_feed_posts_count,\n",
    "        \"recent_posts\": posts_sorted_by_date,\n",
    "        \"popular_posts\": posts_sorted_by_likes\n",
    "    }\n",
    "    return profile\n",
    "\n",
    "def print_user_profile(user_profile, n):\n",
    "    print(\"User profile with id:\", user_profile[\"user_id\"])\n",
    "    print(\"Followers count:\", user_profile[\"followers_count\"])\n",
    "    print(\"Following count:\", user_profile[\"following_count\"])\n",
    "    print(\"______________________\\n\")\n",
    "    \n",
    "    print(f\"User posts: ({user_profile['user_posts_count']})\")\n",
    "    for i, post in enumerate(user_profile[\"user_posts\"][:n]):\n",
    "        print(post[\"content\"], \"date:\", post[\"timestamp\"])\n",
    "    print(\"______________________\\n\")\n",
    "    \n",
    "    print(\"Feed (recent):\")\n",
    "    for i, post in enumerate(user_profile[\"recent_posts\"][:n]):\n",
    "        print(post[\"content\"], \"date:\", post[\"timestamp\"])\n",
    "    print(\"______________________\\n\")\n",
    "    \n",
    "    print(\"Feed (popular):\")\n",
    "    for i, post in enumerate(user_profile[\"popular_posts\"][:n]):\n",
    "        print(post[\"content\"], \"likes:\", post.get(\"likes\", \"N/A\"))\n",
    "    print(\"______________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6e6fd",
   "metadata": {},
   "source": [
    "# Insert Data into DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36786a0",
   "metadata": {},
   "source": [
    "## Insert users and following relationships to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a871bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './InputData/twitter_combined.txt'\n",
    "\n",
    "# Read file content\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Prepare data\n",
    "user_pairs = [tuple(map(int, line.strip().split())) for line in lines]\n",
    "\n",
    "# Get a unique set of all users involved\n",
    "all_users = {user for pair in user_pairs for user in pair}\n",
    "\n",
    "# Check which users already exist in the database\n",
    "existing_users = set(users_collection.distinct(\"_id\", {\"_id\": {\"$in\": list(all_users)}}))\n",
    "\n",
    "# Identify new users\n",
    "new_users = all_users - existing_users\n",
    "\n",
    "# Prepare bulk operations for new users\n",
    "user_bulk_operations = [\n",
    "    InsertOne({\"_id\": user_id, \"following_count\": 0, \"followers_count\": 0})\n",
    "    for user_id in new_users\n",
    "]\n",
    "\n",
    "# Execute bulk insert for new users\n",
    "if user_bulk_operations:\n",
    "    users_collection.bulk_write(user_bulk_operations)\n",
    "\n",
    "# Prepare bulk operations for relationships and updating counts\n",
    "relationship_bulk_operations = []\n",
    "user_update_operations = []\n",
    "\n",
    "for user1, user2 in user_pairs:\n",
    "    relationship_bulk_operations.append(InsertOne({\"follower_id\": user1, \"followed_id\": user2}))\n",
    "    user_update_operations.append(UpdateOne({\"_id\": user1}, {\"$inc\": {\"following_count\": 1}}))\n",
    "    user_update_operations.append(UpdateOne({\"_id\": user2}, {\"$inc\": {\"followers_count\": 1}}))\n",
    "\n",
    "# Execute bulk insert for relationships\n",
    "if relationship_bulk_operations:\n",
    "    followers_collection.bulk_write(relationship_bulk_operations)\n",
    "\n",
    "# Execute bulk update for user counts\n",
    "if user_update_operations:\n",
    "    users_collection.bulk_write(user_update_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce03fa",
   "metadata": {},
   "source": [
    "## Assign the input tweets to the influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c303f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting posts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52542/52542 [00:10<00:00, 5126.01it/s]\n"
     ]
    }
   ],
   "source": [
    "top_influencers_list = list(get_most_followed_users(100))\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = './InputData/tweets.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Generate random influencer selections once to avoid repeated random.choice calls\n",
    "influencer_ids = [random.choice(top_influencers_list)['_id'] for _ in range(len(df))]\n",
    "\n",
    "# Function to process each tweet\n",
    "def process_tweet(idx):\n",
    "    tweet_data = df.iloc[idx]\n",
    "    influencer_id = influencer_ids[idx]\n",
    "    date = datetime.strptime(tweet_data['date_time'], '%d/%m/%Y %H:%M')\n",
    "    content = tweet_data['content']\n",
    "    post_id = add_post_without_likes(influencer_id, content, date)\n",
    "    return post_id, influencer_id, content, date\n",
    "\n",
    "# Step 1: Insert all posts first\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    post_data = list(tqdm(executor.map(process_tweet, range(len(df))), total=len(df), desc=\"Inserting posts\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f3338",
   "metadata": {},
   "source": [
    "## Add likes to post randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0940f292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing likes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fetch a pool of random users once\n",
    "user_pool_size = 10000  # Adjust the pool size as needed\n",
    "random_user_pool = get_random_users(user_pool_size, exclude_user_id=None)\n",
    "\n",
    "# Step 2: Insert likes for posts in bulk\n",
    "like_updates = add_likes_bulk(post_data, random_user_pool, max_workers=4)\n",
    "\n",
    "# Step 3: Update post like counts in bulk\n",
    "bulk_updates = [\n",
    "    UpdateOne({\"_id\": post_id}, {\"$set\": {\"likes\": likes}})\n",
    "    for post_id, likes in like_updates\n",
    "]\n",
    "if bulk_updates:\n",
    "    posts_collection.bulk_write(bulk_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4c4b0",
   "metadata": {},
   "source": [
    "## Add indices to collection when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d221ec84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user_id_1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add indices to critical parameters on collections\n",
    "followers_collection.create_index([(\"followed_id\", 1), (\"follower_id\", 1)])\n",
    "\n",
    "posts_collection.create_index([(\"user_id\", 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40510e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [07:12<00:00,  8.16s/it]\n",
      "Processing Temp Feeds: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28401/28401 [02:47<00:00, 169.87it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_feeds_collection = db['temp_feeds']\n",
    "\n",
    "batch_size = 1000  # Define a suitable batch size\n",
    "post_count = posts_collection.count_documents({})\n",
    "num_batches = (post_count // batch_size) + 1\n",
    "\n",
    "# Step 1: Aggregate data into a temporary collection\n",
    "for batch in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "    pipeline = [\n",
    "        {\"$skip\": batch * batch_size},\n",
    "        {\"$limit\": batch_size},\n",
    "        {\"$lookup\": {\n",
    "            \"from\": \"followers\",\n",
    "            \"localField\": \"user_id\",\n",
    "            \"foreignField\": \"followed_id\",\n",
    "            \"as\": \"followers\"\n",
    "        }},\n",
    "        {\"$unwind\": \"$followers\"},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"follower_id\": \"$followers.follower_id\",\n",
    "            \"post\": {\n",
    "                \"post_id\": \"$_id\",\n",
    "                \"user_id\": \"$user_id\",\n",
    "                \"content\": \"$content\",\n",
    "                \"timestamp\": \"$timestamp\",\n",
    "                \"likes\": \"$likes\"\n",
    "            }\n",
    "        }},\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$follower_id\",\n",
    "            \"posts\": {\"$push\": \"$post\"}\n",
    "        }},\n",
    "        {\"$out\": \"temp_feeds\"}\n",
    "    ]\n",
    "    posts_collection.aggregate(pipeline)\n",
    "\n",
    "# Step 2: Process the temporary collection to split large documents\n",
    "temp_docs = list(temp_feeds_collection.find())\n",
    "for doc in tqdm(temp_docs, desc=\"Processing Temp Feeds\"):\n",
    "    follower_id = doc['_id']\n",
    "    posts = doc['posts']\n",
    "    \n",
    "    chunk_size = 100\n",
    "    chunked_posts = [posts[i:i + chunk_size] for i in range(0, len(posts), chunk_size)]\n",
    "    \n",
    "    for chunk in chunked_posts:\n",
    "        feeds_collection.update_one(\n",
    "            {\"user_id\": follower_id},\n",
    "            {\"$push\": {\"posts\": {\"$each\": chunk}}},\n",
    "            upsert=True\n",
    "        )\n",
    "\n",
    "# Step 3: Ensure posts arrays are unique and in order\n",
    "# Use aggregation pipeline to deduplicate and sort posts\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"unique_posts\": {\"$setUnion\": \"$posts\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"user_id\": 1,\n",
    "            \"posts\": {\"$slice\": [{\"$sortArray\": {\"input\": \"$unique_posts\", \"sortBy\": {\"timestamp\": -1}}}, 16793600]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$merge\": {\n",
    "            \"into\": \"feeds\",\n",
    "            \"whenMatched\": \"replace\",\n",
    "            \"whenNotMatched\": \"insert\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "feeds_collection.aggregate(pipeline)\n",
    "\n",
    "# Clean up temporary collection\n",
    "temp_feeds_collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b99cb",
   "metadata": {},
   "source": [
    "# Request data from DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89939c93",
   "metadata": {},
   "source": [
    "## Find out top 100 most followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "120be840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top influencers:\n",
      "user id: 40981798 Follower count 8660\n",
      "user id: 43003845 Follower count 7700\n",
      "user id: 22462180 Follower count 7623\n",
      "user id: 34428380 Follower count 7558\n",
      "user id: 115485051 Follower count 4798\n",
      "user id: 15913 Follower count 4337\n",
      "user id: 3359851 Follower count 3986\n",
      "user id: 11348282 Follower count 3850\n",
      "user id: 7861312 Follower count 3712\n",
      "user id: 27633075 Follower count 3655\n",
      "user id: 31331740 Follower count 3623\n",
      "user id: 18996905 Follower count 3255\n",
      "user id: 7860742 Follower count 3197\n",
      "user id: 813286 Follower count 3172\n",
      "user id: 22784458 Follower count 2974\n",
      "user id: 17868918 Follower count 2904\n",
      "user id: 10671602 Follower count 2874\n",
      "user id: 117674417 Follower count 2858\n",
      "user id: 48485771 Follower count 2725\n",
      "user id: 34068984 Follower count 2693\n",
      "user id: 18927441 Follower count 2680\n",
      "user id: 83943787 Follower count 2678\n",
      "user id: 15853668 Follower count 2634\n",
      "user id: 1183041 Follower count 2593\n",
      "user id: 238260874 Follower count 2560\n",
      "user id: 8088112 Follower count 2539\n",
      "user id: 16464746 Follower count 2425\n",
      "user id: 16098603 Follower count 2399\n",
      "user id: 88323281 Follower count 2356\n",
      "user id: 18776017 Follower count 2346\n",
      "user id: 133055665 Follower count 2342\n",
      "user id: 263838766 Follower count 2317\n",
      "user id: 309366491 Follower count 2291\n",
      "user id: 90420314 Follower count 2241\n",
      "user id: 116036694 Follower count 2238\n",
      "user id: 31353077 Follower count 2209\n",
      "user id: 100318079 Follower count 2208\n",
      "user id: 14654965 Follower count 2122\n",
      "user id: 63485337 Follower count 2095\n",
      "user id: 59804598 Follower count 2083\n",
      "user id: 10350 Follower count 2073\n",
      "user id: 195475105 Follower count 2069\n",
      "user id: 16303106 Follower count 2031\n",
      "user id: 270449528 Follower count 2014\n",
      "user id: 151338729 Follower count 1981\n",
      "user id: 19358562 Follower count 1927\n",
      "user id: 24742040 Follower count 1897\n",
      "user id: 65913144 Follower count 1862\n",
      "user id: 26281970 Follower count 1821\n",
      "user id: 116952434 Follower count 1799\n",
      "user id: 30313925 Follower count 1775\n",
      "user id: 187773078 Follower count 1774\n",
      "user id: 5442012 Follower count 1763\n",
      "user id: 15234657 Follower count 1752\n",
      "user id: 79797834 Follower count 1742\n",
      "user id: 276706356 Follower count 1725\n",
      "user id: 16475194 Follower count 1718\n",
      "user id: 280935165 Follower count 1710\n",
      "user id: 27855118 Follower count 1696\n",
      "user id: 204317520 Follower count 1674\n",
      "user id: 121533789 Follower count 1668\n",
      "user id: 69592091 Follower count 1665\n",
      "user id: 82030021 Follower count 1657\n",
      "user id: 28465635 Follower count 1656\n",
      "user id: 18742444 Follower count 1625\n",
      "user id: 254839786 Follower count 1600\n",
      "user id: 972651 Follower count 1591\n",
      "user id: 47787563 Follower count 1568\n",
      "user id: 7872262 Follower count 1567\n",
      "user id: 14075928 Follower count 1559\n",
      "user id: 783214 Follower count 1550\n",
      "user id: 19040580 Follower count 1536\n",
      "user id: 14922225 Follower count 1529\n",
      "user id: 26929220 Follower count 1528\n",
      "user id: 284422688 Follower count 1524\n",
      "user id: 204140367 Follower count 1520\n",
      "user id: 93905958 Follower count 1496\n",
      "user id: 46423291 Follower count 1493\n",
      "user id: 19493072 Follower count 1491\n",
      "user id: 19802879 Follower count 1480\n",
      "user id: 21681252 Follower count 1479\n",
      "user id: 314316607 Follower count 1479\n",
      "user id: 14230524 Follower count 1472\n",
      "user id: 11928542 Follower count 1467\n",
      "user id: 428333 Follower count 1439\n",
      "user id: 24585498 Follower count 1437\n",
      "user id: 19725644 Follower count 1426\n",
      "user id: 22679419 Follower count 1411\n",
      "user id: 2367911 Follower count 1406\n",
      "user id: 17093617 Follower count 1405\n",
      "user id: 62581962 Follower count 1402\n",
      "user id: 17224642 Follower count 1399\n",
      "user id: 149538028 Follower count 1396\n",
      "user id: 15439395 Follower count 1395\n",
      "user id: 259842341 Follower count 1391\n",
      "user id: 173732041 Follower count 1385\n",
      "user id: 47161442 Follower count 1381\n",
      "user id: 153226312 Follower count 1378\n",
      "user id: 131601987 Follower count 1372\n",
      "user id: 229039814 Follower count 1370\n"
     ]
    }
   ],
   "source": [
    "# Get and print top influencers\n",
    "top_influencers = get_most_followed_users(100)\n",
    "print(\"Top influencers:\")\n",
    "top_influencers_id_list = []\n",
    "for influencer in top_influencers:\n",
    "    print(\"user id:\", influencer[\"_id\"], \"Follower count\", influencer[\"followers_count\"])\n",
    "    top_influencers_id_list.append(influencer[\"_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1dc4ba",
   "metadata": {},
   "source": [
    "## Find out top 100 influencer followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9659e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: User ID 3359851 follows 51 influencers\n",
      "#2: User ID 24641194 follows 43 influencers\n",
      "#3: User ID 18581803 follows 42 influencers\n",
      "#4: User ID 440963134 follows 40 influencers\n",
      "#5: User ID 7872262 follows 40 influencers\n",
      "#6: User ID 364917755 follows 40 influencers\n",
      "#7: User ID 274153775 follows 39 influencers\n",
      "#8: User ID 277649366 follows 38 influencers\n",
      "#9: User ID 358775055 follows 38 influencers\n",
      "#10: User ID 46209291 follows 38 influencers\n",
      "#11: User ID 279787626 follows 38 influencers\n",
      "#12: User ID 463952369 follows 38 influencers\n",
      "#13: User ID 134940306 follows 38 influencers\n",
      "#14: User ID 401313910 follows 38 influencers\n",
      "#15: User ID 439788025 follows 38 influencers\n",
      "#16: User ID 135218281 follows 38 influencers\n",
      "#17: User ID 208132323 follows 38 influencers\n",
      "#18: User ID 157829215 follows 37 influencers\n",
      "#19: User ID 440341213 follows 37 influencers\n",
      "#20: User ID 7860742 follows 37 influencers\n",
      "#21: User ID 461410856 follows 37 influencers\n",
      "#22: User ID 304462046 follows 37 influencers\n",
      "#23: User ID 77618627 follows 37 influencers\n",
      "#24: User ID 430182387 follows 37 influencers\n",
      "#25: User ID 276308596 follows 37 influencers\n",
      "#26: User ID 430268163 follows 37 influencers\n",
      "#27: User ID 94414805 follows 37 influencers\n",
      "#28: User ID 14691709 follows 37 influencers\n",
      "#29: User ID 278652553 follows 37 influencers\n",
      "#30: User ID 18776017 follows 37 influencers\n",
      "#31: User ID 259842341 follows 37 influencers\n",
      "#32: User ID 307458983 follows 37 influencers\n",
      "#33: User ID 236184723 follows 37 influencers\n",
      "#34: User ID 479854996 follows 36 influencers\n",
      "#35: User ID 308723182 follows 36 influencers\n",
      "#36: User ID 153226312 follows 36 influencers\n",
      "#37: User ID 208549187 follows 36 influencers\n",
      "#38: User ID 16098603 follows 36 influencers\n",
      "#39: User ID 451250774 follows 36 influencers\n",
      "#40: User ID 14573745 follows 36 influencers\n",
      "#41: User ID 280935165 follows 36 influencers\n",
      "#42: User ID 317076339 follows 36 influencers\n",
      "#43: User ID 216088014 follows 36 influencers\n",
      "#44: User ID 395559648 follows 36 influencers\n",
      "#45: User ID 214328887 follows 36 influencers\n",
      "#46: User ID 100581193 follows 36 influencers\n",
      "#47: User ID 270449528 follows 36 influencers\n",
      "#48: User ID 57490887 follows 35 influencers\n",
      "#49: User ID 254839786 follows 35 influencers\n",
      "#50: User ID 22841103 follows 35 influencers\n",
      "#51: User ID 195475105 follows 35 influencers\n",
      "#52: User ID 123371682 follows 35 influencers\n",
      "#53: User ID 103598216 follows 35 influencers\n",
      "#54: User ID 204140367 follows 35 influencers\n",
      "#55: User ID 387237264 follows 35 influencers\n",
      "#56: User ID 224309765 follows 35 influencers\n",
      "#57: User ID 318434640 follows 35 influencers\n",
      "#58: User ID 14269220 follows 35 influencers\n",
      "#59: User ID 56860418 follows 35 influencers\n",
      "#60: User ID 280365428 follows 35 influencers\n",
      "#61: User ID 480083825 follows 35 influencers\n",
      "#62: User ID 545020142 follows 35 influencers\n",
      "#63: User ID 67864340 follows 34 influencers\n",
      "#64: User ID 389742937 follows 34 influencers\n",
      "#65: User ID 15846407 follows 34 influencers\n",
      "#66: User ID 314316607 follows 34 influencers\n",
      "#67: User ID 100318079 follows 34 influencers\n",
      "#68: User ID 496438192 follows 34 influencers\n",
      "#69: User ID 145129229 follows 34 influencers\n",
      "#70: User ID 196680777 follows 34 influencers\n",
      "#71: User ID 8470732 follows 34 influencers\n",
      "#72: User ID 160237722 follows 34 influencers\n",
      "#73: User ID 107830991 follows 34 influencers\n",
      "#74: User ID 24081780 follows 34 influencers\n",
      "#75: User ID 302847930 follows 34 influencers\n",
      "#76: User ID 197504076 follows 34 influencers\n",
      "#77: User ID 328590469 follows 34 influencers\n",
      "#78: User ID 235978600 follows 34 influencers\n",
      "#79: User ID 285359479 follows 34 influencers\n",
      "#80: User ID 83943787 follows 33 influencers\n",
      "#81: User ID 406628822 follows 33 influencers\n",
      "#82: User ID 72818790 follows 33 influencers\n",
      "#83: User ID 204317520 follows 33 influencers\n",
      "#84: User ID 523885474 follows 33 influencers\n",
      "#85: User ID 26929220 follows 33 influencers\n",
      "#86: User ID 7846 follows 33 influencers\n",
      "#87: User ID 230880104 follows 33 influencers\n",
      "#88: User ID 493102437 follows 33 influencers\n",
      "#89: User ID 217796457 follows 33 influencers\n",
      "#90: User ID 144631425 follows 33 influencers\n",
      "#91: User ID 232818548 follows 32 influencers\n",
      "#92: User ID 17759701 follows 32 influencers\n",
      "#93: User ID 292632231 follows 32 influencers\n",
      "#94: User ID 14536491 follows 32 influencers\n",
      "#95: User ID 65913144 follows 32 influencers\n",
      "#96: User ID 248883350 follows 32 influencers\n",
      "#97: User ID 5442012 follows 32 influencers\n",
      "#98: User ID 151495845 follows 32 influencers\n",
      "#99: User ID 406476054 follows 32 influencers\n",
      "#100: User ID 181701688 follows 32 influencers\n"
     ]
    }
   ],
   "source": [
    "top_influencer_followers = find_top_users_following_influencers(top_influencers_id_list, 100)\n",
    "\n",
    "# Print the top users\n",
    "for i, doc in enumerate(top_influencer_followers):\n",
    "    print(f\"#{i+1}: User ID {doc['_id']} follows {doc['count']} influencers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce50c0f",
   "metadata": {},
   "source": [
    "## Show user profile (User follower count, user followed count, 25 newest posts in feed, 25 most liked posts in feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d36a084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User profile with id: 22462180\n",
      "Followers count: 7623\n",
      "Following count: 701\n",
      "______________________\n",
      "\n",
      "User posts: (550)\n",
      "HOPE YOU ARE ROARING YOUR WAY TO THE POLLS STILL! ðŸ‘ŠðŸ¼ðŸ¦ðŸ¯â¤ï¸ðŸ‡ºðŸ‡¸: https://t.co/tNQit6ZIA6 date: 2016-11-08 20:04:00\n",
      "@shannonwoodward he didn't go down to the people date: 2016-10-20 02:41:00\n",
      "@HoliestKaty iconic date: 2016-09-18 07:39:00\n",
      "â¤ï¸ðŸ¶I predict maj likes ðŸ¶â¤ï¸ https://t.co/Z1HzbWpZ4g date: 2016-03-01 23:42:00\n",
      "â˜€ï¸â›„ï¸ðŸ’¦ https://t.co/8fCcsmiNvQ https://t.co/dvbWHCYurc date: 2015-11-18 20:09:00\n",
      "conciousness = creativity date: 2015-09-02 22:12:00\n",
      "Happy Father's Day to a guy that did the best job he could. Love you. â¤ï¸ https://t.co/UVwsIcGgN9 date: 2015-06-21 22:06:00\n",
      "Coming for your brand @itsjeremyscott https://t.co/fpCuM19nus date: 2015-04-12 08:41:00\n",
      "Goodnight Sweden: http://t.co/OZleBmLkLj date: 2015-03-22 00:06:00\n",
      "Just had 1st FaceTime Thanksgiving! What I would give 2b scraping marshmallow off of sweet potato, wearing fuzzy socks &amp; holding my niece! ðŸ˜© date: 2014-11-28 02:51:00\n",
      "I DID IT. Finally, after all these years talkin bout it I done climbed your bridge tonight Sydney!â€¦ http://t.co/awnjnXbHOK date: 2014-11-23 11:03:00\n",
      "SO happy that my tour gets to learn the gift of Transcendental Meditation today! Imagine theâš¡ï¸that's gonna come out of us moving forward! ðŸ™‡ date: 2014-10-05 20:22:00\n",
      "Be a fountain, not a drain. date: 2014-09-12 20:43:00\n",
      "Maybe no one told them about the ðŸ’‹? ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ðŸ™ date: 2014-07-01 22:36:00\n",
      "Went and got cultured today n saw Time Machine, an exhibition by Joana Vasconcelos at Manchester Artâ€¦ http://t.co/FBft6auWvv date: 2014-05-22 18:10:00\n",
      "RISE AND SHINE! â˜€ï¸ Mohegan Sun pre-sale starts right now! http://t.co/ErkQottOCU date: 2014-02-26 15:04:00\n",
      "Exactly what you should be. â€œ@PrismaticPerry: What am I doing with my life? @katyperry  http://t.co/qfnGjT4beR http://t.co/QSFU0Mwqasâ€ date: 2014-02-14 23:07:00\n",
      "Honored to be curating Art for Freedom w/ @Madonna this month! Make 2014 a year of social change. Submit your art at http://t.co/KcidTOg6X8 date: 2014-01-08 01:44:00\n",
      "Family 1st! @DemiLovve: @katyperry made the whole family listen to ur new song, turned off the tv &amp; sat them down at the table #DarkHorse!! date: 2013-09-17 07:21:00\n",
      "ðŸ‘Š â€œ@RossMonroe22: @katyperry KATY I SEE IT http://t.co/oBHBRbhkivâ€ date: 2013-07-31 02:07:00\n",
      "Just had an elegant unveiling of my new fragrance ðŸŒ¹KILLER QUEENðŸŒ¹ at the Duke! Can't wait to share the royal juice! #sosophisticated date: 2013-05-03 01:45:00\n",
      "You know the 90's are back when you're voluntarily putting record scratches in your songs a la Portishead's Dummy. date: 2013-04-19 04:46:00\n",
      "Discovered one of my favorite Hirsts tonight! Had to have my picture with it. http://t.co/PXUtyUOGZT date: 2013-03-31 08:37:00\n",
      "Putting my freakum dress on and gonna go howl at the full moon. date: 2012-09-30 07:13:00\n",
      "Tomorrow #whereareunowOZNZ https://t.co/wXCUiFQ4Rc date: 2016-10-02 16:48:00\n",
      "______________________\n",
      "\n",
      "Feed (recent):\n",
      "NO FUCKING WAY.. THIS IS WHY I LOVE YOU BRAZIL ðŸ’–ðŸ’–ðŸ’–ðŸ’– https://t.co/04DzNtYPWG date: 2015-07-01 13:32:00\n",
      "#NMN #nomakeupmonday http://t.co/LdAbm0F4h4 ðŸ’œðŸ’œðŸ’œ https://t.co/1ORBOAYqGd date: 2015-06-29 21:21:00\n",
      "Saaaannngggin my ass off right now... ðŸŽ¶ðŸ’– date: 2015-06-29 03:05:00\n",
      "Fuck yeah America #LovesWins ðŸŒˆðŸŽ‰ðŸ’– date: 2015-06-26 19:36:00\n",
      "#7YearsOfCampRock... How incredible. 7 years since my life changed and my dreams came true. I love you all so much.. We rock!! ðŸ˜ date: 2015-06-21 06:05:00\n",
      "Worldwide #SaturdayOnline listeners ask me anything here: http://t.co/T2Y7qWYwXb &amp; watch my @AskAnythingChat with @OnAirRomeo #4thOfJuly ðŸ˜œðŸ˜œ date: 2015-06-21 00:39:00\n",
      "Sometimes... I just want a peanut butter jelly sandwich and a juice box. date: 2015-06-17 21:27:00\n",
      "@JessKarpinski we can do it date: 2015-06-15 04:36:00\n",
      "And no she didn't ask me to tweet it.. I'm tweeting it because of how proud I am of her so if you haven't checked it out - go NOW!!! date: 2015-06-11 15:47:00\n",
      "LIVE from Flight Ihavenoidea: DRAMA UNFOLDS AS TWO PASSENGERS REFUSE TO CHECK CARRY ONS.. #livetweet #yourwelcome date: 2015-06-07 12:33:00\n",
      "Soooo.... I'm on a plane and we aren't taking off because this girl and her mom don't want to check their carry-ons. Where's the popcorn?! date: 2015-06-07 12:29:00\n",
      "@Alex_Music555 that is so incredible!! Please do!! date: 2015-05-28 02:11:00\n",
      "Sweat pants, crime shows and Buddy..... Where are you @WValderrama?? ðŸ’”ðŸ”«ðŸ’‰ðŸ”ªðŸ¶ date: 2015-05-28 02:05:00\n",
      "I've never felt more comfortable and confident in my skin than I did today... Recovery and body acceptance IS possible!!!! date: 2015-05-27 23:58:00\n",
      "I really wish I could stop for all you guys outside right now but sometimes it gets a little too overwhelming.. Please don't be mad ðŸ˜£ date: 2015-05-27 22:33:00\n",
      "Like.... Stfu with how cute he is..... ðŸ˜­ðŸ˜ https://t.co/joA6xzyirB date: 2015-05-27 11:57:00\n",
      "Very grateful for this man... Ladies and gentlemen.. David Massey!! Finally we can post a picâ€¦ https://t.co/sdZ95KnsSS date: 2015-05-27 03:27:00\n",
      "Within the past 2 weeks I have spent 49 hours in an airplane. What is life..... date: 2015-05-24 03:10:00\n",
      "Guys!! Tonight go watch my buddy @beaucaspersmart judge #FAKEOFF on @truTV 10/9c and watch the crews fake famous cities!! date: 2015-05-21 03:37:00\n",
      "Holls ðŸ’–ðŸ‘¯ðŸ˜ #Vietnam #demiworldtour https://t.co/SGgmc3UY5T date: 2015-05-10 18:00:00\n",
      "Sometimes I fall asleep on my mom's face....... ðŸ’¤ðŸ’— https://t.co/7DNzv2bRWU date: 2015-04-29 00:34:00\n",
      "Looks like I'm actually singing the song ðŸ˜ðŸ’°ðŸ’°ðŸ’°ðŸ”«ðŸ”«ðŸ”« #bitchbettahavemy... #demiworldtour https://t.co/9G0X3ZqN4c date: 2015-04-24 13:36:00\n",
      "BOOTS ðŸ’‹â¤ï¸ðŸ‘  #demiworldtour https://t.co/tyX7OLILfe date: 2015-04-24 05:32:00\n",
      "In honor of our former escapades, I thought you'd like this to remember your first blaze.. Happy #420â€¦ https://t.co/D6p3RMzhJj date: 2015-04-20 08:55:00\n",
      "#Sydney #demiworldtour ðŸ’—ðŸ’œðŸŒŸ https://t.co/IbuAV3KXng date: 2015-04-19 07:35:00\n",
      "______________________\n",
      "\n",
      "Feed (popular):\n",
      "Ps. There's a Walburger here ðŸ˜±ðŸ” likes: 99\n",
      "Sometimes... I just want a peanut butter jelly sandwich and a juice box. likes: 98\n",
      "Soooo.... I'm on a plane and we aren't taking off because this girl and her mom don't want to check their carry-ons. Where's the popcorn?! likes: 97\n",
      "BOOTS ðŸ’‹â¤ï¸ðŸ‘  #demiworldtour https://t.co/tyX7OLILfe likes: 97\n",
      "My boys are really sleepy..... And I'm the luckiest woman in the world.... ðŸ’¤ðŸ™ðŸ’• http://t.co/8m1zBXtxsB likes: 97\n",
      "ðŸ‘€ #wheresdemi #iseeyou http://t.co/zBNAtmEYuk likes: 96\n",
      "#NoMakeupMonday â˜€ï¸ðŸ˜ŽðŸŒ´ #NMM #devonnebydemi http://t.co/PfGJMeuO0t Now send me yours!!!!! https://t.co/Sn7qHZ2For likes: 95\n",
      "@Alex_Music555 that is so incredible!! Please do!! likes: 91\n",
      "Sweat pants, crime shows and Buddy..... Where are you @WValderrama?? ðŸ’”ðŸ”«ðŸ’‰ðŸ”ªðŸ¶ likes: 85\n",
      "Saaaannngggin my ass off right now... ðŸŽ¶ðŸ’– likes: 80\n",
      "My happy place ðŸ™ŒðŸ™ https://t.co/pbbEz9tlff likes: 80\n",
      "#Sydney #demiworldtour ðŸ’—ðŸ’œðŸŒŸ https://t.co/IbuAV3KXng likes: 79\n",
      "So empowered by the #SB49 @Always ad. Iâ€™m proud to sing #LikeAGirl!! What do you do #LikeAGirl?! http://t.co/SinBKziSOa  #ad likes: 78\n",
      "Worldwide #SaturdayOnline listeners ask me anything here: http://t.co/T2Y7qWYwXb &amp; watch my @AskAnythingChat with @OnAirRomeo #4thOfJuly ðŸ˜œðŸ˜œ likes: 77\n",
      "So.... Apparently my friend is a ghost. ðŸ‘»ðŸ˜³ https://t.co/jIH9sTIfqO likes: 76\n",
      "Hold on.... So people actually see white and gold....??!! ðŸ˜°ðŸ˜± likes: 76\n",
      "Sometimes I fall asleep on my mom's face....... ðŸ’¤ðŸ’— https://t.co/7DNzv2bRWU likes: 75\n",
      "Btw.... Excited to get back in the studio in days.... Are you guys ready for album #5??? ðŸ˜œ likes: 75\n",
      "LIVE from Flight Ihavenoidea: DRAMA UNFOLDS AS TWO PASSENGERS REFUSE TO CHECK CARRY ONS.. #livetweet #yourwelcome likes: 72\n",
      "Looks like I'm actually singing the song ðŸ˜ðŸ’°ðŸ’°ðŸ’°ðŸ”«ðŸ”«ðŸ”« #bitchbettahavemy... #demiworldtour https://t.co/9G0X3ZqN4c likes: 71\n",
      "GOOD MORNING â˜€ï¸â˜•ï¸ðŸ’• a little late for the #NMM but, here ya go!!!! Keeping my skin really clear withâ€¦ http://t.co/RVcYkXjWaD likes: 70\n",
      "Very grateful for this man... Ladies and gentlemen.. David Massey!! Finally we can post a picâ€¦ https://t.co/sdZ95KnsSS likes: 69\n",
      "@graham_caitie that looks awesome!!! likes: 66\n",
      "I LITERALLY JUST SAID \"I'm gonna film this because she's probably gonna finish this in SECONDS.\"â€¦ https://t.co/OeGmtC5OLX likes: 65\n",
      "I was in my 1st Twister commercial at 10, now Iâ€™m in another! Canâ€™t wait 4 u guys 2 see it!!! #LetsMove #TwisterMoves http://t.co/WET0ZJEcwc likes: 64\n",
      "______________________\n"
     ]
    }
   ],
   "source": [
    "# Get and print user profile\n",
    "user_id = 22462180\n",
    "tweets_to_show = 25\n",
    "user_profile = get_user_profile(user_id)\n",
    "print_user_profile(user_profile, tweets_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8ab90",
   "metadata": {},
   "source": [
    "## 25 most popular posts that contain given words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96124357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 2\n",
      "Post content: Several @twittereng folks teamed up with @UCBerkeley for a course about analyzing big data: @UCBTweeter. http://t.co/5SUkxQJr\n",
      "Post content: Twitter + the Human Face of Big Data: http://t.co/HlpWw7rV @faceofbigdata #HFOBD / #BigDataChat 11am PT/2pm ET Friday 10/19 w/@isaach\n"
     ]
    }
   ],
   "source": [
    "words_to_search = [\"big\", \"data\"]\n",
    "result = get_posts_with_words(words_to_search)\n",
    "\n",
    "# Print the count of posts found\n",
    "print(\"Number of posts:\", result[\"count\"])\n",
    "\n",
    "# Iterate over and print each post content\n",
    "for post in result[\"posts\"]:\n",
    "    print(\"Post content:\", post[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed336184",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb94af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users_collection.drop()\n",
    "# followers_collection.drop()\n",
    "# posts_collection.drop()\n",
    "# likes_collection.drop()\n",
    "# feeds_collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cf83358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
